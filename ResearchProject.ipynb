{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6100844",
   "metadata": {},
   "source": [
    "# Research on embedding and similarity search on python for eCRF "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eec7e56",
   "metadata": {},
   "source": [
    "# Index\n",
    "\n",
    "[1. Research on embedding and similarity search on python for eCRF](#research-on-embedding-and-similarity-search-on-python-for-ecrf)  \n",
    "[2. REQUIREMENTS](#requirements)  \n",
    "[3. Task 1A: Text extraction from a pdf](#task-1a--text-extraction-from-a-pdf)  \n",
    "[4. Task 1B: Pdf to image + OCR on the image.](#task-1b-pdf-to-image--ocr-on-the-image)  \n",
    "[5. Task 2: Embedding for a similarity search using AI](#task-2-embedding-for-a-similarity-search-using-ai)  \n",
    "[6. Task 3: Get the questionnaire from Milo's API](#task-3-get-the-questionnaire-from-milos-api)  \n",
    "[7. References & Sources][def]  \n",
    "\n",
    "\n",
    "[def]: #references--sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252f9b85",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## REQUIREMENTS\n",
    "\n",
    "- ideally, install Bash. \n",
    "```bash\n",
    "brew install bash #MacOS\n",
    "https://www.howtogeek.com/790062/how-to-install-bash-on-windows-11/ #Windows\n",
    "```\n",
    "- the one from windows is a tutorial, you will need to use a virtual machine. You could also do the installation on powershell but some commands don't even exist for it. \n",
    "\n",
    "- Should work for most previous versions but I am using a python 3.12.3 kernel.\n",
    "\n",
    "- create a .env file with the environment variables. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aebd82",
   "metadata": {},
   "source": [
    "\n",
    "# Task 1A : Text extraction from a pdf\n",
    "We must retrieve the plain text from a pdf file and identify the questions in a questionnaire. \n",
    "For our final product this might not even be useful because a lot of the documents will simply be scanned. \n",
    "\n",
    "[Task 1: PDF Extraction](./task1_PDFextraction.ipynb)\n",
    "\n",
    "That being said, if one had to be chosen, I would go with PyMuPDF for its undeniable superiority. It is quicker and the text extracted is more accurate.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442bfd8f",
   "metadata": {},
   "source": [
    "# Task 1B: Pdf to image + OCR on the image.\n",
    "\n",
    "[Task 1B: pdf to Image](./task1b_PDFtoImage.ipynb)\n",
    "\n",
    "The best way to turn a pdf into an image, is not as easily found. The quickest way it the library pdfium2, however, I think PyMuPDF is an option worth considering becuase it can easily denoise the image and make it black and white. These two extra features and the fact that it is the best text retriever, make it according to me the best option. \n",
    "\n",
    "[Task 1C: OCR on the Image](./task1c_OCRonImage.ipynb)\n",
    "\n",
    "\n",
    "After carefully reviewing, all the open source models can simply be forgotten. Those who perform well like easy OCR are extremely slow and thus getting a working product would be impossible. EasyOCR used with a good GPU would be good, but still it has trouble detecting double lined cells in tables. \n",
    "\n",
    "[Task 1C: Paid OCR Services](./task1c_PaidOCR.ipynb)\n",
    "\n",
    "In terms of paid OCR, the best options I have found are Google Gemini 2.5 from Google Vertex AI and Meta Llama 4 Maverick. Maverick doesn't have coordinates but is by far the best at properly detecting layout. I might develop two prototypes, one with maverick and pytesseract and the other only with google Vertex AI. \n",
    "\n",
    "TODO: add them to the price comparison. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b375467",
   "metadata": {},
   "source": [
    "# Task 2: Embedding for a similarity search using AI\n",
    "\n",
    "### Embedding \n",
    "stands for associating values to multidimensional vectors to perform searches on the text of said documents\n",
    "\n",
    "[Task 2a: Denoising text with an LLM](./task2a_denoisingLLM.ipynb)\n",
    "\n",
    "[Task 2b: Embedding](./task2b_Embedding.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caa4145",
   "metadata": {},
   "source": [
    "# Task 3: Get the questionnaire from Milo's API\n",
    "\n",
    "[Task 3 : API retrieval](./task3:getQuestionnaireMilo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab915126",
   "metadata": {},
   "source": [
    "# References & Sources\n",
    "\n",
    "[1] Deepseek Team, Deepseek: Quick doubts, definitions, and explanations. [Online]. Available: https://deepseek.com\n",
    "\n",
    "[2] GeeksforGeeks Team, “Extract text from PDF file using Python,” GeeksforGeeks. [Online]. Available: https://www.geeksforgeeks.org/extract-text-from-pdf-file-using-python/\n",
    "\n",
    "[3] J. Singer-Vine, pdfplumber Documentation. [Online]. Available: https://github.com/jsvine/pdfplumber\n",
    "\n",
    "[4] B. Rogojan, “How to automate PDF data extraction: 3 different methods to parse PDFs for analytics,” Seattle Data Guy. [Online]. Available: https://www.theseattledataguy.com/how-to-automate-pdf-data-extraction-3-different-methods-to-parse-pdfs-for-analytics/#page-content\n",
    "\n",
    "[5] Python Software Foundation, “time — Time access and conversions,” Python Documentation. [Online]. Available: https://docs.python.org/3/library/time.html\n",
    "\n",
    "[6] Google, Tesseract OCR. [Online]. Available: https://github.com/tesseract-ocr/tesseract\n",
    "\n",
    "[7] S. Hoffstaetter, pytesseract GitHub Repository. [Online]. Available: https://github.com/madmaze/pytesseract\n",
    "\n",
    "[8] J. Jerphanion, pdf2image GitHub Repository. [Online]. Available: https://github.com/Belval/pdf2image\n",
    "\n",
    "[9] S. Dufour, PyPDF2 GitHub Repository. [Online]. Available: https://github.com/sdpython/PyPDF2\n",
    "\n",
    "[10] PyMuPDF Team, PyMuPDF GitHub Repository. [Online]. Available: https://github.com/pymupdf/PyMuPDF\n",
    "\n",
    "[11] J. J. Vens, pdfminer.six GitHub Repository. [Online]. Available: https://github.com/pdfminer/pdfminer.six\n",
    "\n",
    "[12] E. Berger, Scalene GitHub Repository. [Online]. Available: https://github.com/plasma-umass/scalene?tab=readme-ov-file\n",
    "\n",
    "[13] E. Berger, “Scalene: A high-performance, high-precision CPU, GPU, and memory profiler for Python,” YouTube. [Online]. Available: https://www.youtube.com/watch?v=5iEf-_7mM1k\n",
    "\n",
    "[14] Z. Shen, R. Zhang, M. Dell, B. C. G. Lee, J. Carlson, and W. Li, “LayoutParser: A Unified Toolkit for Deep Learning Based Document Image Analysis,” arXiv preprint arXiv:2103.15348, 2021. [Online]. Available: https://github.com/Layout-Parser/layout-parser/tree/main\n",
    "\n",
    "[15] LayoutParser Team, “EfficientDet Model for PubLayNet,” Hugging Face. [Online]. Available: https://huggingface.co/layoutparser/efficientdet/tree/main/PubLayNet/tf_efficientdet_d1\n",
    "\n",
    "[16] PyPDFium2 Team, PyPDFium2 GitHub Repository. [Online]. Available: https://github.com/pypdfium2-team\n",
    "\n",
    "[17] E. McConville, Wand GitHub Repository. [Online]. Available: https://github.com/emcconville/wand?tab=readme-ov-file\n",
    "\n",
    "[18] Wand Documentation, “Install Wand on Debian,” Wand. [Online]. Available: https://docs.wand-py.org/en/latest/guide/install.html#install-wand-debian\n",
    "\n",
    "[19] J. Alankrita, pdftotext GitHub Repository. [Online]. Available: https://github.com/jalan/pdftotext\n",
    "\n",
    "[20] JaidedAI Team, EasyOCR GitHub Repository. [Online]. Available: https://github.com/JaidedAI/EasyOCR\n",
    "\n",
    "[21] PaddlePaddle Team, PaddleOCR GitHub Repository. [Online]. Available: https://github.com/PaddlePaddle/PaddleOCR\n",
    "\n",
    "[22] UKPLab Team, SentenceTransformers GitHub Repository. [Online]. Available: https://github.com/UKPLab/sentence-transformers\n",
    "\n",
    "[23] TensorFlow Team, “Semantic Similarity with TensorFlow Hub Universal Encoder,” GitHub Repository. [Online]. Available: https://github.com/tensorflow/docs/blob/master/site/en/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder.ipynb\n",
    "\n",
    "[24] Explosion Team, spaCy GitHub Repository. [Online]. Available: https://github.com/explosion/spaCy\n",
    "\n",
    "[25] Hugging Face, Qwen2.5-VL-72B-Instruct Model Card. [Online]. Available: https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct?inference_provider=nebius\n",
    "\n",
    "[26] Meta, Llama-3.2-11B-Vision-Instruct Model Card. [Online]. Available: https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct?inference_provider=hf-inference\n",
    "\n",
    "[27] Groq, Llama-4-Scout-17B-16E-Instruct Model Documentation. [Online]. Available: https://console.groq.com/docs/model/llama-4-scout-17b-16e-instruct\n",
    "\n",
    "[28] Groq, Llama-4-Maverick-17B-128E-Instruct Model Documentation. [Online]. Available: https://console.groq.com/docs/model/llama-4-maverick-17b-128e-instruct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
