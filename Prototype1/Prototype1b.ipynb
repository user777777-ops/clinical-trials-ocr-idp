{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8aaf4e8",
   "metadata": {},
   "source": [
    "# Prototype 1b, tests on pdf 2\n",
    "**Stack:**\n",
    "```\n",
    "OCR: Gemini 2.5 flash\n",
    "Embeddings: gemini-embedding-exp-03-07\n",
    "LLM: Gemini 2.5 flash\n",
    "\n",
    "```\n",
    "It requires credentials, you will need to download googles authentication CLI. Check their [official documentation](https://cloud.google.com/vision/docs/authentication)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd505cf",
   "metadata": {},
   "source": [
    "> Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "865a78be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-genai in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (1.22.0)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from google-genai) (4.9.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from google-genai) (2.40.3)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from google-genai) (2.11.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from google-genai) (2.32.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from google-genai) (8.5.0)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from google-genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from google-genai) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.4.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home//Documents/clinical-trials-ocr-idp/.venv/lib/python3.13/site-packages (from requests) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade google-genai\n",
    "%pip install python-dotenv\n",
    "%pip install requests\n",
    "%pip install faiss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "545181bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "OCR_API_KEY=os.environ.get(\"GCV_API_KEY\")\n",
    "EMBEDDINGS_API_KEY=os.environ.get(\"GEMINI_API_KEY\")\n",
    "MILO_API_KEY=os.environ.get(\"MILO_API_KEY\")\n",
    "doc_path=\"Note_clinique_chambre_implantable_2.pdf\"\n",
    "questionnaire_id = 1182 # Update this to the correct questionnaire ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc386e1a",
   "metadata": {},
   "source": [
    "> OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "504adb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai\n",
    "from google.genai.types import (\n",
    "    GenerateContentConfig,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    "    HttpOptions,\n",
    "    Part,\n",
    "    SafetySetting,\n",
    ")\n",
    "\n",
    "\n",
    "client = genai.Client(http_options=HttpOptions(api_version=\"v1\"), api_key=OCR_API_KEY)\n",
    "\n",
    "\n",
    "# Read the PDF file as bytes\n",
    "with open(doc_path, \"rb\") as pdf_file:\n",
    "    pdf_bytes = pdf_file.read()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\n",
    "        Part.from_bytes(\n",
    "            data=pdf_bytes,\n",
    "            mime_type=\"application/pdf\",\n",
    "        ),\n",
    "        \"\"\"Extract and output the positions of objects and the text in them for each page. Return the output in JSON format without markdown fomatting. Like this:\n",
    "            [\n",
    "                {\n",
    "        \"page\": 1,\n",
    "        \"objects\": [\n",
    "        {\n",
    "            \"box_2d\": [75, 48, 89, 401],\n",
    "            \"text\": \"  \"\n",
    "        }\n",
    "        ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        \"\"\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ac30aa",
   "metadata": {},
   "source": [
    "> Prepare the output for embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "125652f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Nom du patient : Sarah Thompson Date de naissance : 22/03/1990 Âge : 35 ans Taille : 1,63m Poids : 65kg Sexe : Féminin Numéro de dossier médical (NDM) : 987654321 Date de l'intervention : 15/06/2025 Heure : 14h45 à 15h20 Chirurgien responsable : Dr Amanda Lee, MD, PhD Assistant(e)\", \": Jordan Kim, IDE Procédure : Pose d'une chambre d'implantation sous-cutanée crânienne Localisation : Région pariétale gauche Anesthésie : e (Sevoflurane + Propofol IV) Allergies : Aucune allergie médicamenteuse connue (AAMK) --- Note opératoire La patiente a subi avec succès la pose d'une chambre d'implantation crânienne 38L x25-43 à visée\", \"expérimentale, permettant un accès chronique à la surface corticale. L'intervention s'est déroulée sans complication. --- S - Subjectif Patiente de 35 ans, sans antécédents médicaux significatifs, incluse dans un protocole de recherche en neurosciences. Elle consulte pour la mise en place d'une chambre crânienne afin de permettre un accès cortical\", 'répété. Elle ne rapporte aucune plainte préopératoire. Le consentement éclairé a été obtenu. --- O - Objectif Signes vitaux : Stables durant toute la procédure Imagerie préopératoire : IRM cérébrale sans anomalie, localisation adaptée pour la pose Per-opératoire : Préparation du site opératoire sous conditions stériles Craniotomie avec préservation de', \"la dure-mère Mise en place d'une chambre en titane de 25 par 55mm, fixée avec vis et ciment chirurgicalAucun saignement majeur, pas de fuite de LCR Perte sanguine estimée : < 20 mL Post-opératoire immédiat : Érythème léger, pas d'hématome Examen neurologique sans anomalie --- A - Analyse État postopératoire\", \"stable Pose de chambre d'implantation réussie sans complication Aucun signe d'infection ou de déficit neurologique Tolérance anesthésique et chirurgicale excellente --- P - Plan Traitement médicamenteux : Céfazoline 1g IV toutes les 8h pendant 24h – prophylaxie antibiotique Paracétamol 650 mg per os toutes les 6h si besoin – gestion\", \"de la douleur Ondansetron 4 mg IV toutes les 8h si besoin – prévention des nausées Soins postopératoires : Pansement à maintenir pendant 48 heures Premier changement de pansement : 17/06/2025Surveillance des signes d'infection ou de fuite de LCR Ablation des points dans 10 à 14 jours Éviter tout effort\", 'physique intense pendant 2 semaines Rendez-vous de suivi en neurochirurgie dans une semaine']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "response_json=json.loads(response.text)\n",
    "all_text = \" \".join(\n",
    "    obj.get(\"text\", obj.get(\"text_content\", \"\")) \n",
    "    for page in response_json \n",
    "    for obj in page[\"objects\"]\n",
    ")\n",
    "all_words=all_text.split()\n",
    "chunk_size=50\n",
    "split_size=len(all_words) //chunk_size\n",
    "embed_input=[]\n",
    "for i in range(split_size):\n",
    "    embed_input.append(\" \".join(all_words[i*chunk_size:(i+1)*chunk_size]))\n",
    "embed_input.append(\" \".join(all_words[split_size*chunk_size:]))\n",
    "print(embed_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278be023",
   "metadata": {},
   "source": [
    "> Getting the survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "070dc96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 6920, 'questionTitle': 'Sex du patient', 'questionType': 'DROPDOWN', 'options': [{'id': 44594, 'label': 'Male'}, {'id': 44595, 'label': 'Female'}]}, {'id': 6921, 'questionTitle': 'Taille (en cm)', 'questionType': 'DECIMAL'}, {'id': 6922, 'questionTitle': 'Poids (en Kg)', 'questionType': 'DECIMAL'}, {'id': 6923, 'questionTitle': 'Date de naissance', 'questionType': 'YEAR_AND_MONTH'}]\n",
      "['Sex du patient', 'Taille (en cm)', 'Poids (en Kg)', 'Date de naissance']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_questionnaire_data(questionnaire_id):\n",
    " \n",
    "    # Replace with your API key\n",
    "    api_key = MILO_API_KEY\n",
    "    \n",
    "    # Replace with the URL you want to access\n",
    "    url = f\"https://dev.milo-dct-backend.com:8443/api/v1/questionnaires/{questionnaire_id}/questions-ai\"\n",
    " \n",
    "    # Headers to include the API key\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    " \n",
    "    # Make the GET request\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    " \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # or response.text\n",
    "    else:\n",
    "        print(f\"Request failed with status code : {response.status_code}\")\n",
    "        return response.text\n",
    "    \n",
    "data = (get_questionnaire_data(questionnaire_id))\n",
    "print(data)\n",
    "\n",
    "# Extract question headers\n",
    "question_titles = [question[\"questionTitle\"] for question in data]\n",
    "print(question_titles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de3263",
   "metadata": {},
   "source": [
    "> Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e01768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ContentEmbedding(\n",
      "  values=[\n",
      "    -0.025878742,\n",
      "    0.0020673582,\n",
      "    0.013390861,\n",
      "    -0.059618957,\n",
      "    -0.011064952,\n",
      "    <... 3067 more items ...>,\n",
      "  ]\n",
      "), ContentEmbedding(\n",
      "  values=[\n",
      "    -0.007082646,\n",
      "    0.0068139415,\n",
      "    -0.001481578,\n",
      "    -0.06914881,\n",
      "    -0.008830571,\n",
      "    <... 3067 more items ...>,\n",
      "  ]\n",
      "), ContentEmbedding(\n",
      "  values=[\n",
      "    -0.019181354,\n",
      "    0.015095852,\n",
      "    -0.0021383704,\n",
      "    -0.054811887,\n",
      "    -0.013169268,\n",
      "    <... 3067 more items ...>,\n",
      "  ]\n",
      "), ContentEmbedding(\n",
      "  values=[\n",
      "    -0.009992672,\n",
      "    -0.001156016,\n",
      "    0.0018930413,\n",
      "    -0.06021864,\n",
      "    -0.009157293,\n",
      "    <... 3067 more items ...>,\n",
      "  ]\n",
      "), ContentEmbedding(\n",
      "  values=[\n",
      "    0.010657949,\n",
      "    0.010105528,\n",
      "    -0.00038620213,\n",
      "    -0.06531801,\n",
      "    -0.013499003,\n",
      "    <... 3067 more items ...>,\n",
      "  ]\n",
      "), ContentEmbedding(\n",
      "  values=[\n",
      "    -0.007613509,\n",
      "    0.002130284,\n",
      "    0.011550773,\n",
      "    -0.07004851,\n",
      "    -0.0072456836,\n",
      "    <... 3067 more items ...>,\n",
      "  ]\n",
      "), ContentEmbedding(\n",
      "  values=[\n",
      "    -0.0044787005,\n",
      "    -0.011329949,\n",
      "    -0.0012316856,\n",
      "    -0.05515312,\n",
      "    -0.012763001,\n",
      "    <... 3067 more items ...>,\n",
      "  ]\n",
      "), ContentEmbedding(\n",
      "  values=[\n",
      "    0.0106669925,\n",
      "    0.00018233477,\n",
      "    0.010169162,\n",
      "    -0.06737984,\n",
      "    -0.024629965,\n",
      "    <... 3067 more items ...>,\n",
      "  ]\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "client = genai.Client(api_key=EMBEDDINGS_API_KEY)\n",
    "embedded_text = client.models.embed_content(\n",
    "        model=\"gemini-embedding-exp-03-07\",\n",
    "        contents=embed_input,\n",
    "        config=types.EmbedContentConfig(task_type=\"SEMANTIC_SIMILARITY\")\n",
    ")\n",
    "embedded_questions = client.models.embed_content(\n",
    "        model=\"gemini-embedding-exp-03-07\",\n",
    "        contents=question_titles,\n",
    "        config=types.EmbedContentConfig(task_type=\"SEMANTIC_SIMILARITY\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d31b30",
   "metadata": {},
   "source": [
    "> Performing a similarity search with the faiss library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cb46c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# Convert Gemini embeddings to numpy arrays\n",
    "answer_embeddings = np.array([e.values for e in embedded_text.embeddings], dtype=np.float32)\n",
    "question_embeddings = np.array([e.values for e in embedded_questions.embeddings], dtype=np.float32)\n",
    "\n",
    "dimension = answer_embeddings.shape[1]\n",
    "\n",
    "# Normalize for cosine similarity\n",
    "faiss.normalize_L2(answer_embeddings)\n",
    "faiss.normalize_L2(question_embeddings)\n",
    "\n",
    "# Create the FAISS index for cosine similarity\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "index.add(answer_embeddings)\n",
    "\n",
    "# Search for the nearest neighbors\n",
    "k = 3\n",
    "D, I = index.search(question_embeddings, k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63f5cc3",
   "metadata": {},
   "source": [
    "> Prepare the text and parse it for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b8eb490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sex du patient': 'Féminin', 'Male': 'Not found in context.', 'Female': 'Féminin', 'Taille (en cm)': '1,63m', 'Poids (en Kg)': '65kg', 'Date de naissance': '22/03/1990'}\n"
     ]
    }
   ],
   "source": [
    "subQuestions = [question.get(\"options\", []) for question in data]\n",
    "all_answers = {}\n",
    "for i in range(len(subQuestions)):\n",
    "    # Combine main and subquestions into a flat list\n",
    "    LLMquestions = [question_titles[i]] + [q[\"label\"] for q in subQuestions[i]]\n",
    "    questions_str = \"\\n\".join(f\"- {q}\" for q in LLMquestions)\n",
    "\n",
    "    # Build context string\n",
    "    LLMcontext = []\n",
    "    for j in range(k):\n",
    "        idx = I[i][j]\n",
    "        if idx < len(embed_input):\n",
    "            LLMcontext.append(embed_input[idx])\n",
    "    context_str = \"\\n\".join(LLMcontext)\n",
    "\n",
    "    # Generate response\n",
    "    response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\n",
    "        f\"\"\"\n",
    "    Answer the following questions using only the information from the context.\n",
    "    Return your answers as a single JSON object without markdown quotes, with each question as a key and the answer as the value.\n",
    "    If an answer is not found in the context, use \"Not found in context.\" as the value.\n",
    "    DO NOT CHANGE THE FORMAT. ex:1,63m is not changed to 163cm\n",
    "    Questions:\n",
    "    {questions_str}\n",
    "\n",
    "    Context:\n",
    "    {context_str}\n",
    "    \"\"\"\n",
    "        ],\n",
    "    )\n",
    "        #  Parse the JSON response\n",
    "    try:\n",
    "        answer_dict = json.loads(response.text)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Warning: Could not parse response as JSON:\", response.text)\n",
    "        continue\n",
    "\n",
    "    # Update the cumulative dictionary\n",
    "    all_answers.update(answer_dict)\n",
    "\n",
    "# Now all_answers contains all the merged results\n",
    "print(all_answers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b952f05d",
   "metadata": {},
   "source": [
    "> Read the output with json and put the values in a list for highlighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e652e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "searchValues=set(list(all_answers.values())) # Here we store the values in a list, and remove the repeated ones. \n",
    "#we get back the list from the beggining response_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c238b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find bounding boxes for each value\n",
    "results = []\n",
    "for page in response_json:\n",
    "    page_num = page.get(\"page\", None)\n",
    "    for obj in page[\"objects\"]:\n",
    "        for value in searchValues:\n",
    "            if value in obj[\"text\"]:\n",
    "                results.append({\n",
    "                    \"value\": value,\n",
    "                    \"box_2d\": obj[\"box_2d\"],\n",
    "                    \"text\": obj[\"text\"],\n",
    "                    \"page\": page_num\n",
    "                })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17fd64e",
   "metadata": {},
   "source": [
    "> Now we highlight the pdf at the relevant places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c619d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "# === Open the PDF ===\n",
    "doc = fitz.open(doc_path)\n",
    "output_path=doc_path+\"highlighted.pdf\"\n",
    "# === Highlight each box on the correct page ===\n",
    "\n",
    "# Convert Gemini coordinates to actual PDF coordinates\n",
    "def convert_gemini_to_pdf(box_2d, pdf_width, pdf_height):\n",
    "    # Gemini format: [top, left, bottom, right] in 1000x1000 scale\n",
    "    # Convert to actual image coordinates first\n",
    "    top = (box_2d[0] / 1000) * pdf_height\n",
    "    left = (box_2d[1] / 1000) * pdf_width  \n",
    "    bottom = (box_2d[2] / 1000) * pdf_height\n",
    "    right = (box_2d[3] / 1000) * pdf_width\n",
    "    \n",
    "    # Return in PyMuPDF format: [left, top, right, bottom]\n",
    "    return [left, top, right, bottom]\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    page_num = result[\"page\"] - 1  # PyMuPDF uses 0-based page numbers\n",
    "    box = result[\"box_2d\"]\n",
    "    # Get page dimensions\n",
    "    pdf_width = page.rect.width\n",
    "    pdf_height = page.rect.height\n",
    "    # If box = [top, left, bottom, right], convert to [left, top, right, bottom]\n",
    "    x0, y0, x1, y1 =convert_gemini_to_pdf(box,pdf_width,pdf_height) \n",
    "    rect = fitz.Rect(x0, y0, x1, y1)\n",
    "    page = doc[page_num]\n",
    "    annot = page.add_rect_annot(rect)\n",
    "    annot.set_colors(stroke=(1, 1, 0), fill=(1, 1, 0))  # Yellow\n",
    "    annot.set_opacity(0.4)  # Semi-transparent\n",
    "    annot.update()\n",
    "\n",
    "\n",
    "# === Save the highlighted PDF ===\n",
    "doc.save(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
